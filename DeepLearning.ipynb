{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0R+cN2b/CGayuGRjQo7LB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thePegasusai/CloudPhone/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SCBNZlhWjqJu",
        "outputId": "97b9dbb2-5248-484e-e15d-936f4749bede"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-82a52af49c8e>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy\u001b[0m\n\u001b[0m                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ],
      "source": [
        "#To create a deep learning model for sorting through quantum computing queries in the fastest way possible, the model should be trained on a dataset of quantum computing queries, and then be able to predict the best query to use for a given input. Here is an example of a code snippet for a deep learning model to do this:\n",
        "\n",
        "\n",
        "#Import the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To generate a code example of using Hugging Face AI search engine, you can use the following code snippet:\n",
        "\n",
        "import transformers\n",
        "model = transformers.AutoModelWithLMHead.from_pretrained('AI-Search-Engine')\n",
        "query = \"What is the meaning of life?\"\n",
        "result = model.generate(query, max_length=128, top_p=0.9, top_k=5)\n",
        "print(result)\n",
        "\n",
        "# This code snippet will generate the most likely result from the Hugging Face AI search engine given the query \"What is the meaning of life?\". The max_length parameter determines the maximum length of the generated result, top_p determines the percentage of the most likely results to keep, and top_k determines the number of words from the input query to consider for the generated result.\n"
      ],
      "metadata": {
        "id": "VfePZjb6kyv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#                                                                         #\n",
        "###########################################################################\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers, models, optimizers, datasets, utils \n",
        "import matplotlib.pyplot as plt \n",
        "from IPython import display\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "def get_data():    # Get the data from MNIST Dataset and return it in batches of size = batch_size = 32  \n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()   # Load the dataset using keras function load data from mnist dataset\n",
        "\n",
        "    x_train = x_train / 255.0      # Normalize the values between 0 and 1 for better convergence in training process \n",
        "\n",
        "    x_test = x_test / 255.0        # Normalize the values between 0 and 1 for better convergence in testing process \n",
        "\n",
        "    train=utils.Sequence(x=x_train[:],y=y_train[:])       # Create a sequence object to feed into model while training with generator API which will be used by dataloader API to generate batches of images at each epochs when training is done on GPU's memory  \n",
        "\n",
        "    test=utils.Sequence(x=x_test[:],y=y_test[:])           # Create a sequence object to feed into model while testing with generator API which will be used by dataloader API to generate batches of images at each epochs when testing is done on GPU's memory  \n",
        "\n",
        "    return train , test         # Return both train and test sequences objects created above for use later on during training or testing respectively\n"
      ],
      "metadata": {
        "id": "0yyxxFm4prRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#                                                                         #\n",
        "###########################################################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_test, yhat):  # pragma: no cover\n",
        "\n",
        "    cm = confusion_matrix(y_test, yhat)  # Compute confusion matrix\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    print(cm)  # Show confusion matrix in console\n",
        "\n",
        "    fig = plt.figure()  # Create figure object to plot on it later on...\n",
        "\n",
        "    ax = fig.add_subplot(111)  # Add a sub-plot (1 row x 1 column grid of plots) and get its handle...\n",
        "\n",
        "    cax = ax.matshow(cm)  # Plot the normalized Confusion Matrix using matshow function from MatPlotLib library...\n",
        "\n",
        "    fig.colorbar(cax)  # Add color bar to show the values of different colors in our plot...\n",
        "\n",
        "    ticks = np.arange(len(np.unique([y for y in yhat]))) + 0.5  \t# Set ticks at center of each cell with labels from unique classes (0 -> 9)...\n",
        "    \t\t\t\t\t\t  \t# ...and add 0.5 because we want integer values for tick marks but we start from index 0 instead of 1 like usual MatPlotLib convention...\n",
        "    \t       \t     \t     \t      //// NOTE: This is not necessary if you use \"plt\" instead of \"fig\".../////       ...but I prefer this way :)! :D :D :D <3 <3 <3 <3 <3 <3 .........<*^*>......................<*^*>..........................<*^*>............................................<|><|><|><|><|><|><|>><<<<<<<<<<<<<<>>>>>>>>>>>>>>>.......>>>>>>>>>>>>>>>>>>>>>.>>>>>>>>>>>>>>>>>>>.............>>.<||||||\n"
      ],
      "metadata": {
        "id": "4w8MxBTlprek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}