{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thePegasusai/CloudPhone/blob/main/Text_to_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, you will need to install the tensorflow library. You can do this by running the following command in a code cell:"
      ],
      "metadata": {
        "id": "jlFObBywVAVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "XRRR2gP9VLQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, you will need to import the TensorFlow.js library and enable the TensorFlow.js-backed execution environment. You can do this by running the following code:"
      ],
      "metadata": {
        "id": "BIqpLC4vVPw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "tf.enable_eager_execution()\n"
      ],
      "metadata": {
        "id": "yBgmNh9xVUql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can define a function that takes a sequence of text inputs and generates a sequence of images. Here is an example of how you can do this using the Pillow library to draw text on an image:"
      ],
      "metadata": {
        "id": "CAmBQikBVbNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Set the size of the images\n",
        "WIDTH = 640\n",
        "HEIGHT = 480\n",
        "\n",
        "# Set the font and font size\n",
        "FONT = ImageFont.truetype(\"arial.ttf\", 36)\n",
        "\n",
        "def text_to_image(text):\n",
        "    \"\"\"Convert a sequence of text inputs to a sequence of images.\"\"\"\n",
        "    for t in text:\n",
        "        # Create a blank image\n",
        "        img = Image.new(\"RGB\", (WIDTH, HEIGHT), color=(255, 255, 255))\n",
        "\n",
        "        # Draw the text on the image\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        draw.text((10, 10), t, font=FONT, fill=(0, 0, 0))\n",
        "\n",
        "        # Convert the image to a tensor\n",
        "        img = tf.convert_to_tensor(tfio.image.encode_jpeg(img).numpy())\n",
        "\n",
        "        # Yield the image tensor\n",
        "        yield img\n"
      ],
      "metadata": {
        "id": "Ka5McDMJVmLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use TensorFlow.js to create a video from the sequence of images. Run the following code to do this:"
      ],
      "metadata": {
        "id": "ZyewiaicVwR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the video parameters\n",
        "fps = 30\n",
        "codec = \"vp9\"\n",
        "\n",
        "# Set the text inputs\n",
        "text = [\"Text input 1\", \"Text input 2\", \"Text input 3\"]\n",
        "\n",
        "# Create a dataset from the text inputs\n",
        "dataset = tf.data.Dataset.from_generator(lambda: text_to_image(text), tf.string, tf.TensorShape([]))\n",
        "\n",
        "# Create a video writer\n",
        "writer = tfio.videowriter.VideoWriter(\"video.mp4\", fps=fps, codec=codec, width=WIDTH, height=HEIGHT)\n",
        "\n",
        "# Write the video\n",
        "for img in dataset:\n",
        "    writer.write(img)\n",
        "\n",
        "# Close the video writer\n",
        "writer.close()\n",
        "\n",
        "#  This will create a new video file called video.mp4 in the current directory that contains the sequence of text inputs as images.\n",
        "  "
      ],
      "metadata": {
        "id": "LNEUy_jFV1ZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}