{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YghDRHmmymVr5CCt8jvdszu6UuSy5gRh",
      "authorship_tag": "ABX9TyNfZzfPi2OwI22+UjeTxn2A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thePegasusai/CloudPhone/blob/main/Cloudphone_ar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbHNZ53Sqbdo"
      },
      "outputs": [],
      "source": [
        "#  mobility phone from the cloud to accomplish milestones"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assets"
      ],
      "metadata": {
        "id": "TMc_SWjjq-cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#site assets (gif)\n",
        "=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/0 (2).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/0 (1).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/0 (4).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/0 (5).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/0.gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/1 (1).gif\" height=\"200\" width=\"200\"> \n",
        "  <img src=\"assets/DeepFakes/1.gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/2 (1).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/2 (2).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/2 (3).gif\" height=\"200\" width=\"200\">\n",
        "  <img src=\"assets/DeepFakes/2.gif\" height=\"200\" width=\"200\">\n",
        "    "
      ],
      "metadata": {
        "id": "a2lguQYKcPUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "697ac0d8-bb7c-4901-d8f3-8b9c26c181bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f2f504aede5b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    =\"200\" width=\"200\">\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jina"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa0dFefzqwBn",
        "outputId": "725ffb2c-17d6-43e0-c928-4b5af7c9a46f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jina\n",
            "  Downloading jina-3.13.1.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 34.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jcloud>=0.0.35\n",
            "  Downloading jcloud-0.1.6.tar.gz (27 kB)\n",
            "Collecting grpcio-health-checking<1.48.1,>=1.46.0\n",
            "  Downloading grpcio_health_checking-1.47.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from jina) (1.10.2)\n",
            "Collecting docarray>=0.16.4\n",
            "  Downloading docarray-0.20.1.tar.gz (651 kB)\n",
            "\u001b[K     |████████████████████████████████| 651 kB 56.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi>=0.76.0\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from jina) (6.0)\n",
            "Collecting opentelemetry-exporter-prometheus>=1.12.0rc1\n",
            "  Downloading opentelemetry_exporter_prometheus-1.12.0rc1-py3-none-any.whl (10 kB)\n",
            "Collecting jina-hubble-sdk>=0.26.12\n",
            "  Downloading jina_hubble_sdk-0.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-aiohttp-client>=0.33b0\n",
            "  Downloading opentelemetry_instrumentation_aiohttp_client-0.36b0-py3-none-any.whl (11 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.13.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.15.0-py3-none-any.whl (20 kB)\n",
            "Collecting uvicorn[standard]\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from jina) (3.8.3)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting aiostream\n",
            "  Downloading aiostream-0.4.5-py3-none-any.whl (35 kB)\n",
            "Collecting opentelemetry-exporter-otlp>=1.12.0\n",
            "  Downloading opentelemetry_exporter_otlp-1.15.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from jina) (2.23.0)\n",
            "Collecting protobuf>=3.20.0\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting grpcio<1.48.1,>=1.46.0\n",
            "  Downloading grpcio-1.47.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 62.0 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-sdk>=1.14.0\n",
            "  Downloading opentelemetry_sdk-1.15.0-py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-grpc>=0.35b0\n",
            "  Downloading opentelemetry_instrumentation_grpc-0.36b0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.12.0 in /usr/local/lib/python3.8/dist-packages (from jina) (0.15.0)\n",
            "Collecting docker\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 77.4 MB/s \n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-fastapi>=0.33b0\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.36b0-py3-none-any.whl (11 kB)\n",
            "Collecting uvloop\n",
            "  Downloading uvloop-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 64.0 MB/s \n",
            "\u001b[?25hCollecting grpcio-reflection<1.48.1,>=1.46.0\n",
            "  Downloading grpcio_reflection-1.47.2-py3-none-any.whl (16 kB)\n",
            "Collecting pathspec\n",
            "  Downloading pathspec-0.10.3-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-api>=1.12.0\n",
            "  Downloading opentelemetry_api-1.15.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from jina) (1.21.6)\n",
            "Collecting websockets\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from jina) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from jina) (3.8.2)\n",
            "Collecting rich>=12.0.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting starlette==0.22.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi>=0.76.0->jina) (4.4.0)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi>=0.76.0->jina) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.8/dist-packages (from grpcio<1.48.1,>=1.46.0->jina) (1.15.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from jcloud>=0.0.35->jina) (2.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (6.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina) (22.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.26.12->jina) (5.1.0)\n",
            "Collecting deprecated>=1.2.6\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-api>=1.12.0->jina) (57.4.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.12.0->jina) (1.14.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.15.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.15.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.57.0)\n",
            "Collecting opentelemetry-proto==1.15.0\n",
            "  Downloading opentelemetry_proto-1.15.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting backoff<3.0.0,>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.36b0\n",
            "  Downloading opentelemetry_semantic_conventions-0.36b0-py3-none-any.whl (26 kB)\n",
            "Collecting opentelemetry-instrumentation==0.36b0\n",
            "  Downloading opentelemetry_instrumentation-0.36b0-py3-none-any.whl (24 kB)\n",
            "Collecting opentelemetry-util-http==0.36b0\n",
            "  Downloading opentelemetry_util_http-0.36b0-py3-none-any.whl (6.7 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.36b0\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.36b0-py3-none-any.whl (13 kB)\n",
            "Collecting asgiref~=3.0\n",
            "  Downloading asgiref-3.6.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->jina) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->jina) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->jina) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->jina) (3.0.4)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=12.0.0->docarray>=0.16.4->jina) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting docker\n",
            "  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 78.2 MB/s \n",
            "\u001b[?25h  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 81.3 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.26.12->jina) (3.11.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]->jina) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting watchfiles>=0.13\n",
            "  Downloading watchfiles-0.18.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 70.5 MB/s \n",
            "\u001b[?25hCollecting httptools>=0.5.0\n",
            "  Downloading httptools-0.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
            "\u001b[K     |████████████████████████████████| 427 kB 77.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: jina, docarray, jcloud, python-multipart\n",
            "  Building wheel for jina (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jina: filename=jina-3.13.1-py3-none-any.whl size=317331 sha256=971a39f5797f0da6b46c1c59f46560ff74d0827577d5adc8f54404ddbec19433\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/59/50/6a95786c6ef1ace54635f9c0bf4d2283b35e9eb7a4667ea7f8\n",
            "  Building wheel for docarray (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docarray: filename=docarray-0.20.1-py3-none-any.whl size=712520 sha256=4bb08a69109f5dff7bb41f8c3c99f04a70be5be8b129dc35183fa9f1084ad6c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/7e/a4/cbebd49dcbd2f704da0202b469d883931c24ac78ab365aca23\n",
            "  Building wheel for jcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jcloud: filename=jcloud-0.1.6-py3-none-any.whl size=31539 sha256=a053810ed3558a591217d50eb25841ebb8523d98ef8cc4c54cc053aa6beea7ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/2d/e1/2f81f08a9d0fd2e631315f9a2006cdfd0a0dac62d89822bc1e\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=928afef198f8be9f403a6a0e9baf9174214c64d7f88877477e39040ff35c9bbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built jina docarray jcloud python-multipart\n",
            "Installing collected packages: deprecated, websocket-client, sniffio, protobuf, opentelemetry-semantic-conventions, opentelemetry-api, commonmark, rich, pathspec, opentelemetry-util-http, opentelemetry-sdk, opentelemetry-proto, opentelemetry-instrumentation, h11, grpcio, docker, backoff, asgiref, anyio, websockets, watchfiles, uvloop, uvicorn, starlette, python-dotenv, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, jina-hubble-sdk, httptools, python-multipart, opentelemetry-instrumentation-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-aiohttp-client, opentelemetry-exporter-prometheus, opentelemetry-exporter-otlp, jcloud, grpcio-reflection, grpcio-health-checking, fastapi, docarray, aiostream, aiofiles, jina\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.47.2 which is incompatible.\u001b[0m\n",
            "Successfully installed aiofiles-22.1.0 aiostream-0.4.5 anyio-3.6.2 asgiref-3.6.0 backoff-2.2.1 commonmark-0.9.1 deprecated-1.2.13 docarray-0.20.1 docker-5.0.3 fastapi-0.88.0 grpcio-1.47.2 grpcio-health-checking-1.47.2 grpcio-reflection-1.47.2 h11-0.14.0 httptools-0.5.0 jcloud-0.1.6 jina-3.13.1 jina-hubble-sdk-0.29.0 opentelemetry-api-1.15.0 opentelemetry-exporter-otlp-1.15.0 opentelemetry-exporter-otlp-proto-grpc-1.15.0 opentelemetry-exporter-otlp-proto-http-1.15.0 opentelemetry-exporter-prometheus-1.12.0rc1 opentelemetry-instrumentation-0.36b0 opentelemetry-instrumentation-aiohttp-client-0.36b0 opentelemetry-instrumentation-asgi-0.36b0 opentelemetry-instrumentation-fastapi-0.36b0 opentelemetry-instrumentation-grpc-0.36b0 opentelemetry-proto-1.15.0 opentelemetry-sdk-1.15.0 opentelemetry-semantic-conventions-0.36b0 opentelemetry-util-http-0.36b0 pathspec-0.10.3 protobuf-4.21.12 python-dotenv-0.21.0 python-multipart-0.0.5 rich-12.6.0 sniffio-1.3.0 starlette-0.22.0 uvicorn-0.20.0 uvloop-0.17.0 watchfiles-0.18.1 websocket-client-1.4.2 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tf-q17TmuvH",
        "outputId": "843545f5-bd62-4ff5-89fb-a31b25c55742"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docarray in /usr/local/lib/python3.8/dist-packages (0.20.1)\n",
            "Requirement already satisfied: jina-hubble-sdk>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from docarray) (0.29.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.8/dist-packages (from docarray) (12.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from docarray) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (5.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.8.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (6.0)\n",
            "Requirement already satisfied: pathspec in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (0.10.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.8/dist-packages (from jina-hubble-sdk>=0.24.0->docarray) (5.0.3)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich>=12.0.0->docarray) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich>=12.0.0->docarray) (4.4.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich>=12.0.0->docarray) (0.9.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (22.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp->jina-hubble-sdk>=0.24.0->docarray) (2.10)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from docker->jina-hubble-sdk>=0.24.0->docarray) (1.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->jina-hubble-sdk>=0.24.0->docarray) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->jina-hubble-sdk>=0.24.0->docarray) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->jina-hubble-sdk>=0.24.0->docarray) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.24.0->docarray) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DocArray is a library for nested, unstructured, multimodal data in transit, including text, image, audio, video, 3D mesh, etc. It allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer multimodal data with a Pythonic API.\n",
        "\n",
        "#🚪 Door to multimodal world: super-expressive data structure for representing complicated/mixed/nested text, image, video, audio, 3D mesh data. The foundation data structure of Jina, CLIP-as-service, DALL·E Flow, DiscoArt etc.\n",
        "\n",
        "#🧑‍🔬 Data science powerhouse: greatly accelerate data scientists’ work on embedding, k-NN matching, querying, visualizing, evaluating via Torch/TensorFlow/ONNX/PaddlePaddle on CPU/GPU.\n",
        "\n",
        "#🚡 Data in transit: optimized for network communication, ready-to-wire at anytime with fast and compressed serialization in Protobuf, bytes, base64, JSON, CSV, DataFrame. Perfect for streaming and out-of-memory data.\n",
        "\n",
        "#🔎 One-stop k-NN: Unified and consistent API for mainstream vector databases that allows nearest neighbor search including Elasticsearch, Redis, AnnLite, Qdrant, Weaviate.\n",
        "\n",
        "#👒 For modern apps: GraphQL support makes your server versatile on request and response; built-in data validation and JSON Schema (OpenAPI) help you build reliable web services.\n",
        "\n",
        "#🐍 Pythonic experience: as easy as a Python list. If you can Python, you can DocArray. Intuitive idioms and type annotation simplify the code you write.\n",
        "\n",
        "#🛸 IDE integration: pretty-print and visualization on Jupyter notebook and Google Colab; comprehensive autocomplete and type hints in PyCharm and VS Code.\n",
        "import docarray\n",
        "docarray.__version__\n",
        "'0.1.0'\n",
        "from docarray import Document, DocumentArray"
      ],
      "metadata": {
        "id": "ErKJSIdKmvBi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "R_z_hoaZp17s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ],
      "metadata": {
        "id": "YCQ6qgoZnH8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "t4PpeRm0citc",
        "outputId": "9454734e-ae5e-4ade-9f4f-3fe8f9246ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gumroad "
      ],
      "metadata": {
        "id": "DHa-21A7jnZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gumroad api\n",
        "!pip install pygumroad\n",
        "!git clone https://github.com/opsdisk/pygumroad.git"
      ],
      "metadata": {
        "id": "N2oTWAn_ccmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4dbae7fa-e18b-4d10-b880-b2bff80b2093"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygumroad\n",
            "  Downloading pygumroad-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting requests>=2.24.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt>=0.9.1\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pygumroad) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pygumroad) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pygumroad) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pygumroad) (1.24.3)\n",
            "Installing collected packages: requests, requests-toolbelt, pygumroad\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\n",
            "Successfully installed pygumroad-0.0.2 requests-2.28.1 requests-toolbelt-0.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pygumroad'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 40 (delta 11), reused 24 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd pygumroad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8WE7WRgnNiu",
        "outputId": "49f22374-7671-4907-a2a9-12e15dcaa979"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pygumroad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ex95GVKenIne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dalle 2 pytorch = text to image"
      ],
      "metadata": {
        "id": "c6wA2s2jm-gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dalle2_pytorch\n",
        "\n",
        "import torch\n",
        "from dalle2_pytorch import CLIP\n",
        "\n",
        "clip = CLIP(\n",
        "    dim_text = 512,\n",
        "    dim_image = 512,\n",
        "    dim_latent = 512,\n",
        "    num_text_tokens = 49408,\n",
        "    text_enc_depth = 1,\n",
        "    text_seq_len = 256,\n",
        "    text_heads = 8,\n",
        "    visual_enc_depth = 1,\n",
        "    visual_image_size = 256,\n",
        "    visual_patch_size = 32,\n",
        "    visual_heads = 8,\n",
        "    use_all_token_embeds = True,            # whether to use fine-grained contrastive learning (FILIP)\n",
        "    decoupled_contrastive_learning = True,  # use decoupled contrastive learning (DCL) objective function, removing positive pairs from the denominator of the InfoNCE loss (CLOOB + DCL)\n",
        "    extra_latent_projection = True,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
        "    use_visual_ssl = True,                  # whether to do self supervised learning on images\n",
        "    visual_ssl_type = 'simclr',             # can be either 'simclr' or 'simsiam', depending on using DeCLIP or SLIP\n",
        "    use_mlm = False,                        # use masked language learning (MLM) on text (DeCLIP)\n",
        "    text_ssl_loss_weight = 0.05,            # weight for text MLM loss\n",
        "    image_ssl_loss_weight = 0.05            # weight for image self-supervised learning loss\n",
        ").cuda()\n",
        "\n",
        "# mock data\n",
        "\n",
        "text = torch.randint(0, 49408, (4, 256)).cuda()\n",
        "images = torch.randn(4, 3, 256, 256).cuda()\n",
        "\n",
        "# train\n",
        "\n",
        "loss = clip(\n",
        "    text,\n",
        "    images,\n",
        "    return_loss = True              # needs to be set to True to return contrastive loss\n",
        ")\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "# do the above with as many texts and images as possible in a loop\n",
        "\n",
        "# train decoder\n",
        "import torch\n",
        "from dalle2_pytorch import Unet, Decoder, CLIP\n",
        "\n",
        "# trained clip from step 1\n",
        "\n",
        "clip = CLIP(\n",
        "    dim_text = 512,\n",
        "    dim_image = 512,\n",
        "    dim_latent = 512,\n",
        "    num_text_tokens = 49408,\n",
        "    text_enc_depth = 1,\n",
        "    text_seq_len = 256,\n",
        "    text_heads = 8,\n",
        "    visual_enc_depth = 1,\n",
        "    visual_image_size = 256,\n",
        "    visual_patch_size = 32,\n",
        "    visual_heads = 8\n",
        ").cuda()\n",
        "\n",
        "# unet for the decoder\n",
        "\n",
        "unet = Unet(\n",
        "    dim = 128,\n",
        "    image_embed_dim = 512,\n",
        "    cond_dim = 128,\n",
        "    channels = 3,\n",
        "    dim_mults=(1, 2, 4, 8)\n",
        ").cuda()\n",
        "\n",
        "# decoder, which contains the unet and clip\n",
        "\n",
        "decoder = Decoder(\n",
        "    unet = unet,\n",
        "    clip = clip,\n",
        "    timesteps = 100,\n",
        "    image_cond_drop_prob = 0.1,\n",
        "    text_cond_drop_prob = 0.5\n",
        ").cuda()\n",
        "\n",
        "# mock images (get a lot of this)\n",
        "\n",
        "images = torch.randn(4, 3, 256, 256).cuda()\n",
        "\n",
        "# feed images into decoder\n",
        "\n",
        "loss = decoder(images)\n",
        "loss.backward()\n",
        "\n",
        "# do the above for many many many many steps\n",
        "# then it will learn to generate images based on the CLIP image embeddings"
      ],
      "metadata": {
        "id": "ZszL9TiL3rFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dalle2_pytorch import Unet, Decoder, CLIP\n",
        "\n",
        "# trained clip from step 1\n",
        "\n",
        "clip = CLIP(\n",
        "    dim_text = 512,\n",
        "    dim_image = 512,\n",
        "    dim_latent = 512,\n",
        "    num_text_tokens = 49408,\n",
        "    text_enc_depth = 1,\n",
        "    text_seq_len = 256,\n",
        "    text_heads = 8,\n",
        "    visual_enc_depth = 1,\n",
        "    visual_image_size = 256,\n",
        "    visual_patch_size = 32,\n",
        "    visual_heads = 8\n",
        ").cuda()\n",
        "\n",
        "# unet for the decoder\n",
        "\n",
        "unet = Unet(\n",
        "    dim = 128,\n",
        "    image_embed_dim = 512,\n",
        "    cond_dim = 128,\n",
        "    channels = 3,\n",
        "    dim_mults=(1, 2, 4, 8)\n",
        ").cuda()\n",
        "\n",
        "# decoder, which contains the unet and clip\n",
        "\n",
        "decoder = Decoder(\n",
        "    unet = unet,\n",
        "    clip = clip,\n",
        "    timesteps = 100,\n",
        "    image_cond_drop_prob = 0.1,\n",
        "    text_cond_drop_prob = 0.5\n",
        ").cuda()\n",
        "\n",
        "# mock images (get a lot of this)\n",
        "\n",
        "images = torch.randn(4, 3, 256, 256).cuda()\n",
        "\n",
        "# feed images into decoder\n",
        "\n",
        "loss = decoder(images)\n",
        "loss.backward()\n",
        "\n",
        "# do the above for many many many many steps\n",
        "# then it will learn to generate images based on the CLIP image embeddings"
      ],
      "metadata": {
        "id": "KjATUg5e8KG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}